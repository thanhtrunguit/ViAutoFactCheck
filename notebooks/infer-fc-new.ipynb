{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13368335,"sourceType":"datasetVersion","datasetId":8480546},{"sourceId":13493120,"sourceType":"datasetVersion","datasetId":8566919},{"sourceId":13495228,"sourceType":"datasetVersion","datasetId":8568289},{"sourceId":13620027,"sourceType":"datasetVersion","datasetId":8655868},{"sourceId":13629445,"sourceType":"datasetVersion","datasetId":8662657},{"sourceId":13629523,"sourceType":"datasetVersion","datasetId":8662717},{"sourceId":13632709,"sourceType":"datasetVersion","datasetId":8664990},{"sourceId":13653120,"sourceType":"datasetVersion","datasetId":8679725},{"sourceId":13655548,"sourceType":"datasetVersion","datasetId":8681506},{"sourceId":13706514,"sourceType":"datasetVersion","datasetId":8719345},{"sourceId":13706785,"sourceType":"datasetVersion","datasetId":8719514}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install transformers==4.55.2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T13:24:17.250067Z","iopub.execute_input":"2025-11-12T13:24:17.250754Z","iopub.status.idle":"2025-11-12T13:24:31.987337Z","shell.execute_reply.started":"2025-11-12T13:24:17.250728Z","shell.execute_reply":"2025-11-12T13:24:31.986481Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting transformers==4.55.2\n  Downloading transformers-4.55.2-py3-none-any.whl.metadata (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.2) (3.19.1)\nCollecting huggingface-hub<1.0,>=0.34.0 (from transformers==4.55.2)\n  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.2) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.2) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.2) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.2) (2025.9.18)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.2) (2.32.5)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.2) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.2) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.2) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.55.2) (2025.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.55.2) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.55.2) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.55.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.55.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.55.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.55.2) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.55.2) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.55.2) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.55.2) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.55.2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.55.2) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.55.2) (2025.8.3)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.55.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.55.2) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.55.2) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.55.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.55.2) (2024.2.0)\nDownloading transformers-4.55.2-py3-none-any.whl (11.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: huggingface-hub, transformers\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 1.0.0rc2\n    Uninstalling huggingface-hub-1.0.0rc2:\n      Successfully uninstalled huggingface-hub-1.0.0rc2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.53.3\n    Uninstalling transformers-4.53.3:\n      Successfully uninstalled transformers-4.53.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface-hub-0.36.0 transformers-4.55.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport logging\nlogging.disable(logging.WARNING)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T13:04:17.144925Z","iopub.execute_input":"2025-11-12T13:04:17.145685Z","iopub.status.idle":"2025-11-12T13:04:17.150014Z","shell.execute_reply.started":"2025-11-12T13:04:17.145654Z","shell.execute_reply":"2025-11-12T13:04:17.149366Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# !pip install -U \"huggingface_hub[cli]\"\n!hf auth login --token ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Load the CSV file\ndf = pd.read_csv(\"/kaggle/input/vinum-qa-viwiki-model/vinum_QA_viwiki_model.csv\")\n\n# Filter rows where 'evidence' is NaN\nna_samples = df[df['evidence'].isna()]\n\n# Print how many there are\nprint(f\"Number of rows with evidence == NaN: {len(na_samples)}\\n\")\n\n# Display the first few examples\nprint(na_samples)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EVAL TOP 1","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom tqdm import tqdm\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# -----------------------------\n# Normalizer (your provided function)\n# -----------------------------\ndef normalize_text(s):\n    \"\"\"Lower, strip, collapse whitespace, remove punctuation for EM/F1 normalization.\"\"\"\n    s = \"\" if s is None else s\n    s = str(s).strip().lower()\n    # Remove punctuation (same approach as many SQuAD eval scripts)\n    s = re.sub(r\"[^\\w\\s]\", \"\", s)\n    s = \" \".join(s.split())\n    return s\n\n# -----------------------------\n# Dataset class (same as training) with minor defensive coercion\n# -----------------------------\nclass SentencePairDataset(Dataset):\n    def __init__(self, sentence_pairs, labels, tokenizer, max_length):\n        self.sentence_pairs = sentence_pairs\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.sentence_pairs)\n\n    def __getitem__(self, idx):\n        sentence1, sentence2 = self.sentence_pairs[idx]\n        label = self.labels[idx]\n\n        # Defensive: coerce to str to avoid tokenizer TypeError\n        s1 = \"\" if sentence1 is None else str(sentence1)\n        s2 = \"\" if sentence2 is None else str(sentence2)\n\n        encoding = self.tokenizer.encode_plus(\n            s1,\n            text_pair=s2,\n            add_special_tokens=True,\n            max_length=self.max_length,\n            return_token_type_ids=False,\n            padding=\"max_length\",\n            return_attention_mask=True,\n            return_tensors=\"pt\",\n            truncation=True,\n        )\n        return {\n            \"input_ids\": encoding[\"input_ids\"].flatten(),\n            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n            \"label\": torch.tensor(label, dtype=torch.long),\n        }\n\n# -----------------------------\n# NOTE: We no longer need a custom classifier class here because we load\n# AutoModelForSequenceClassification from the Hub (same architecture used in training).\n# -----------------------------\n\n# -----------------------------\n# Load test data (KEEP null/empty predicted evidence — do NOT drop)\n# -----------------------------\ndef load_test_data(test_path, tokenizer, max_length=512):\n    \"\"\"\n    Returns:\n      - dataset (SentencePairDataset) where sentence pair = (claim, predicted_evidence_or_empty_string)\n      - predicted_evidences_raw: list (same order) of original predicted evidence values (may be NaN)\n      - gold_evidences_raw: list of original gold evidence values (may be NaN)\n      - gold_labels_int: list of gold labels as ints\n    \"\"\"\n    valid_labels = {\"Support\", \"Refute\", \"NEI\"}\n    label_mapping = {\"Support\": 0, \"Refute\": 1, \"NEI\": 2}\n\n    df = pd.read_csv(test_path)\n\n    # Keep only rows with valid gold_label values\n    df = df[df[\"gold_label\"].isin(valid_labels)].reset_index(drop=True)\n\n    # Map labels (convert to ints)\n    df[\"gold_label_int\"] = df[\"gold_label\"].map(label_mapping)\n\n    # Keep predicted evidence even if NaN — but the dataset will feed an empty string to tokenizer for NaN.\n    # We keep both \"raw\" lists (can contain NaN) and also the strings used as input to the classifier.\n    predicted_evidences_raw = df[\"evidence\"].tolist() if \"evidence\" in df.columns else [None] * len(df)\n    gold_evidences_raw = df[\"gold_evidence\"].tolist() if \"gold_evidence\" in df.columns else [None] * len(df)\n\n    # Build sentence pairs (claim, predicted_evidence_for_tokenizer) where we coerce NaN -> \"\"\n    pred_evidence_for_input = df[\"evidence\"].fillna(\"\").astype(str).tolist()\n    claims_for_input = df[\"claim\"].fillna(\"\").astype(str).tolist()\n    sentence_pairs = list(zip(claims_for_input, pred_evidence_for_input))\n\n    labels = df[\"gold_label_int\"].tolist()\n\n    dataset = SentencePairDataset(sentence_pairs, labels, tokenizer, max_length)\n    return dataset, predicted_evidences_raw, gold_evidences_raw, labels\n\n# -----------------------------\n# Evaluate function (returns predictions and true labels)\n# -----------------------------\ndef evaluate(model, dataloader, device):\n    model.eval()\n    predictions, true_labels = [], []\n\n    for batch in tqdm(dataloader, desc=\"Evaluating Test Set\"):\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"label\"].to(device)\n\n        with torch.no_grad():\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            # extract logits from ModelOutput\n            logits = outputs.logits if hasattr(outputs, \"logits\") else outputs[0]\n            _, predicted = torch.max(logits, dim=1)\n\n        predictions.extend(predicted.cpu().numpy().tolist())\n        true_labels.extend(labels.cpu().numpy().tolist())\n\n    print(\"\\nTest Set Classification Report (verdict classifier):\")\n    print(classification_report(true_labels, predictions, digits=4, target_names=[\"Support\",\"Refute\",\"NEI\"]))\n    return true_labels, predictions\n\n# -----------------------------\n# Metrics: ER, VC, Strict\n# -----------------------------\ndef compute_er_vc_strict(y_true, y_pred, pred_evidences_raw, gold_evidences_raw):\n    \"\"\"\n    Args:\n      - y_true, y_pred: lists of ints (same order)\n      - pred_evidences_raw: list (may contain NaN or None) predicted evidence strings\n      - gold_evidences_raw: list (may contain NaN or None) gold evidence strings\n\n    Behavior:\n      - Normalizes text using normalize_text and compares for exact equality.\n      - If predicted evidence is missing/empty and gold evidence is non-empty -> ER is considered incorrect.\n      - If both predicted and gold are empty -> ER considered correct (they match after normalization).\n    \"\"\"\n    N = len(y_true)\n    assert N == len(y_pred) == len(pred_evidences_raw) == len(gold_evidences_raw)\n    er_flags = []\n    vc_flags = []\n    strict_flags = []\n\n    for i in range(N):\n        pred_raw = pred_evidences_raw[i]\n        gold_raw = gold_evidences_raw[i]\n\n        # Detect null/empty in original columns\n        pred_is_null = pd.isna(pred_raw) or str(pred_raw).strip() == \"\" or str(pred_raw).lower().strip() == \"nan\"\n\n        # Normalized strings (coerce None->\"\")\n        pred_norm = normalize_text(\"\" if pred_raw is None or (isinstance(pred_raw, float) and np.isnan(pred_raw)) else pred_raw)\n        gold_norm = normalize_text(\"\" if gold_raw is None or (isinstance(gold_raw, float) and np.isnan(gold_raw)) else gold_raw)\n\n        # ER correctness logic:\n        # - if predicted is empty but gold is non-empty => incorrect (explicit requirement)\n        # - else check normalized exact match\n        if pred_is_null:\n            er_correct = False\n        else:\n            er_correct = (pred_norm == gold_norm)\n\n        vc_correct = (y_pred[i] == y_true[i])\n        strict_correct = er_correct and vc_correct\n\n        er_flags.append(er_correct)\n        vc_flags.append(vc_correct)\n        strict_flags.append(strict_correct)\n\n    er_count = sum(er_flags)\n    vc_count = sum(vc_flags)\n    strict_count = sum(strict_flags)\n\n    results = {\n        \"n\": N,\n        \"er_count\": er_count,\n        \"vc_count\": vc_count,\n        \"strict_count\": strict_count,\n        \"er_acc\": er_count / N if N else 0.0,\n        \"vc_acc\": vc_count / N if N else 0.0,\n        \"strict_acc\": strict_count / N if N else 0.0,\n        \"er_flags\": er_flags,\n        \"vc_flags\": vc_flags,\n        \"strict_flags\": strict_flags\n    }\n    return results\n\n# -----------------------------\n# Confusion matrix plotting helper (raw counts)\n# -----------------------------\ndef plot_confusion_matrix_counts(y_true,\n                                 y_pred,\n                                 labels=None,\n                                 figsize=(6,6),\n                                 save_path=None):\n    cm = confusion_matrix(y_true, y_pred)  # integer counts\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n    fig, ax = plt.subplots(figsize=figsize)\n    disp.plot(ax=ax, values_format='d')\n    ax.set_title(\"Confusion Matrix (counts)\")\n    plt.tight_layout()\n    if save_path:\n        plt.savefig(save_path, bbox_inches=\"tight\")\n        print(f\"Saved confusion matrix to: {save_path}\")\n    plt.show()\n\n# -----------------------------\n# MAIN: Load + Test + Compute ER/VC/Strict + Plot CM\n# -----------------------------\nif __name__ == \"__main__\":\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(\"Device:\", device)\n\n    TEST_PATH = \"/kaggle/input/predictions-vinum-sliding-window-top-1/predictions_vinum_sliding_window_top_1.csv\"\n\n    # Config\n    MAX_LENGTH = 512\n    BATCH_SIZE = 8\n    CM_SAVE_PATH = \"/kaggle/working/confusion_matrix_counts.png\"   # set to None if you don't want to save\n    LABEL_NAMES = [\"Support\", \"Refute\", \"NEI\"]\n\n    # -----------------------------\n    # LOAD TOKENIZER + MODEL FROM HF repo (AutoModelForSequenceClassification)\n    # -----------------------------\n    HF_REPO_ID = \"ICTuniverse/CafeBERT-FC-ViNumFC-88-Acc\"   # public repo on HF containing tokenizer & model\n\n    # Load tokenizer from Hub\n    print(\"Loading tokenizer from HF repo:\", HF_REPO_ID)\n    tokenizer = AutoTokenizer.from_pretrained(HF_REPO_ID)\n\n    # Load full sequence classification model from Hub\n    print(\"Loading sequence classification model from HF repo:\", HF_REPO_ID)\n    model = AutoModelForSequenceClassification.from_pretrained(HF_REPO_ID)\n    model.to(device)\n\n    # Load test dataset + dataloader (KEEP rows with null predicted evidence)\n    print(\"Loading test dataset from:\", TEST_PATH)\n    test_dataset, pred_evidences_raw, gold_evidences_raw, gold_labels_int = load_test_data(TEST_PATH, tokenizer, max_length=MAX_LENGTH)\n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n    # Run evaluation (verdict classifier)\n    y_true, y_pred = evaluate(model, test_loader, device)\n\n    # After running evaluation and getting y_pred\n    label_id2name = {0: \"Support\", 1: \"Refute\", 2: \"NEI\"}\n    \n    # Load original CSV again (to keep same order and all columns)\n    df_test = pd.read_csv(TEST_PATH)\n    \n    # Map predicted IDs back to label names\n    pred_labels = [label_id2name[i] for i in y_pred]\n    \n    # Attach to the same filtered dataframe used in evaluation\n    df_filtered = df_test[df_test[\"gold_label\"].isin([\"Support\", \"Refute\", \"NEI\"])].reset_index(drop=True)\n    df_filtered[\"pred_label\"] = pred_labels\n    \n    # Save as new CSV\n    SAVE_PATH = \"/kaggle/working/test_with_predictions.csv\"\n    df_filtered.to_csv(SAVE_PATH, index=False)\n    print(f\"\\nSaved predictions to: {SAVE_PATH}\")\n\n    # Compute ER / VC / Strict\n    metrics = compute_er_vc_strict(y_true, y_pred, pred_evidences_raw, gold_evidences_raw)\n    print(\"\\n=== Retrieval / Verdict / Strict Summary ===\")\n    print(f\"Total samples evaluated: {metrics['n']}\")\n    print(f\"ER correct: {metrics['er_count']} / {metrics['n']}  (ER acc = {metrics['er_acc']:.4f})\")\n    print(f\"VC correct: {metrics['vc_count']} / {metrics['n']}  (VC acc = {metrics['vc_acc']:.4f})\")\n    print(f\"Strict correct (both ER & VC): {metrics['strict_count']} / {metrics['n']}  (Strict acc = {metrics['strict_acc']:.4f})\")\n\n    # Plot confusion matrix with raw counts (no normalization, integer display)\n    if len(y_true) == 0 or len(y_pred) == 0:\n        print(\"No predictions/labels to build confusion matrix.\")\n    else:\n        plot_confusion_matrix_counts(y_true, y_pred, labels=LABEL_NAMES, figsize=(6,6), save_path=CM_SAVE_PATH)\n\n    print(\"Done.\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T13:24:39.313707Z","iopub.execute_input":"2025-11-12T13:24:39.314007Z","iopub.status.idle":"2025-11-12T13:26:10.959030Z","shell.execute_reply.started":"2025-11-12T13:24:39.313982Z","shell.execute_reply":"2025-11-12T13:26:10.958113Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nLoading tokenizer from HF repo: ICTuniverse/CafeBERT-FC-ViNumFC-88-Acc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cba2eb080aed4ea7a9e5b7536ce5945a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77dcec2c9d83407595ea949217ed6df7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8efa6748f8024f87a22faede00f4bd49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f22d0efd112145119850248541946b7d"}},"metadata":{}},{"name":"stdout","text":"Loading sequence classification model from HF repo: ICTuniverse/CafeBERT-FC-ViNumFC-88-Acc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/837 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44133f8bdbeb4a24bae5221dff4a0c8a"}},"metadata":{}},{"name":"stderr","text":"2025-11-12 13:24:56.148339: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762953896.332844      39 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762953896.385268      39 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de50079d5023434c9ca314aa5a9900c0"}},"metadata":{}},{"name":"stdout","text":"Loading test dataset from: /kaggle/input/predictions-vinum-sliding-window-top-1/predictions_vinum_sliding_window_top_1.csv\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Test Set: 100%|██████████| 126/126 [00:52<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTest Set Classification Report (verdict classifier):\n              precision    recall  f1-score   support\n\n     Support     0.8277    0.6597    0.7342       335\n      Refute     0.7655    0.6627    0.7104       335\n         NEI     0.6116    0.8179    0.6999       335\n\n    accuracy                         0.7134      1005\n   macro avg     0.7349    0.7134    0.7148      1005\nweighted avg     0.7349    0.7134    0.7148      1005\n\n\nSaved predictions to: /kaggle/working/test_with_predictions.csv\n\n=== Retrieval / Verdict / Strict Summary ===\nTotal samples evaluated: 1005\nER correct: 572 / 1005  (ER acc = 0.5692)\nVC correct: 717 / 1005  (VC acc = 0.7134)\nStrict correct (both ER & VC): 503 / 1005  (Strict acc = 0.5005)\nSaved confusion matrix to: /kaggle/working/confusion_matrix_counts.png\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x600 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"Done.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# -----------------------------\n# Line-by-line display of incorrect label predictions\n# -----------------------------\ndef print_incorrect_label_predictions_linewise(df, y_true, y_pred, label_names):\n    wrong_idx = [i for i in range(len(y_true)) if y_pred[i] != y_true[i]]\n    print(f\"\\n=== Incorrect Label Predictions (VC mismatches) ===\")\n    print(f\"Total incorrect verdicts: {len(wrong_idx)} / {len(y_true)}\\n\")\n\n    if not wrong_idx:\n        print(\"✅ All verdicts predicted correctly!\")\n        return\n    temp = wrong_idx[:10]\n    for i in temp:\n        claim = str(df.loc[i, \"claim\"]).strip()\n        evidence = str(df.loc[i, \"evidence\"]).strip() if \"evidence\" in df.columns else \"\"\n        gold = label_names[y_true[i]]\n        pred = label_names[y_pred[i]]\n\n        print(f\"[{i}]\")\n        print(f\"Claim: {claim}\")\n        print(f\"Evidence: {evidence}\")\n        print(f\"Gold: {gold}\")\n        print(f\"Pred: {pred}\")\n        print(\"-\" * 80)  # separator\n\n# Usage:\ntest_df = pd.read_csv(TEST_PATH)\nprint_incorrect_label_predictions_linewise(test_df, y_true, y_pred, LABEL_NAMES)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Load the CSV file\ndf = pd.read_csv(\"/kaggle/input/viwiki-top1-bi-encoder-with-evidence/viwiki-top1-bi-encoder-with-evidence.csv\")\n\n# Filter rows where 'evidence' is NaN\nna_samples = df[df['evidence'].isna()]\n\n# Print how many there are\nprint(f\"Number of rows with evidence == NaN: {len(na_samples)}\\n\")\n\n# Display the first few examples\nprint(na_samples)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EVAL TOP K","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport ast\nimport torch\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom tqdm import tqdm\n\n# -----------------------------\n# CONFIG / PATHS\n# -----------------------------\nINPUT_CSV = \"/kaggle/input/predictions-viwiki-cafebert-qa-topk/predictions_viwiki_CafeBert_QA_topk.csv\"\nOUT_CSV = \"predictions_with_pair_labels_top10.csv\"\nHF_REPO_ID = \"ICTuniverse/CafeBERT-FC-one-shot-viwiki\"  \nBATCH_SIZE = 32\nMAX_LENGTH = 256\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# label mapping used by the model (adjust if your classifier uses different mapping)\nINT2LABEL = {0: \"Support\", 1: \"Refute\", 2: \"NEI\"}\n\n# -----------------------------\n# Dataset for (claim, evidence) pairs\n# -----------------------------\nclass SentencePairDataset(Dataset):\n    def __init__(self, sentence_pairs, tokenizer, max_length=256):\n        self.sentence_pairs = sentence_pairs\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.sentence_pairs)\n\n    def __getitem__(self, idx):\n        s1, s2 = self.sentence_pairs[idx]\n        s1 = \"\" if s1 is None else str(s1)\n        s2 = \"\" if s2 is None else str(s2)\n        encoding = self.tokenizer.encode_plus(\n            s1,\n            text_pair=s2,\n            add_special_tokens=True,\n            max_length=self.max_length,\n            truncation=True,\n            padding=\"max_length\",\n            return_attention_mask=True,\n            return_tensors=\"pt\",\n        )\n        return {\n            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n        }\n\n# -----------------------------\n# Load model & tokenizer\n# -----------------------------\nprint(\"Loading tokenizer and model from:\", HF_REPO_ID)\ntokenizer = AutoTokenizer.from_pretrained(HF_REPO_ID)\nmodel = AutoModelForSequenceClassification.from_pretrained(HF_REPO_ID)\nmodel.to(device)\nmodel.eval()\n\n# -----------------------------\n# Read input file and expand pairs\n# -----------------------------\ndf = pd.read_csv(INPUT_CSV)\nrequired = {\"claim\", \"question\", \"cid\", \"evidence\", \"gold_evidence\", \"gold_label\"}\nif not required.issubset(set(df.columns)):\n    raise ValueError(f\"Input CSV must contain columns: {required}. Found: {df.columns.tolist()}\")\n\n# Parse evidence column which may be stringified lists\ndef parse_evidence_cell(x):\n    if pd.isna(x):\n        return [\"\"]\n    if isinstance(x, list):\n        return [(\"\" if (e is None or (isinstance(e, float) and pd.isna(e))) else str(e)) for e in x]\n    if isinstance(x, str):\n        x = x.strip()\n        # Try to parse as Python literal list first\n        if (x.startswith(\"[\") and x.endswith(\"]\")) or (x.startswith(\"(\") and x.endswith(\")\")):\n            try:\n                parsed = ast.literal_eval(x)\n                if isinstance(parsed, (list, tuple)):\n                    return [(\"\" if (e is None or (isinstance(e, float) and pd.isna(e))) else str(e)) for e in parsed]\n            except Exception:\n                pass\n        # fallback: treat as comma-separated string\n        parts = [p.strip() for p in x.split(\",\") if p.strip() != \"\"]\n        if parts:\n            return parts\n        # if non-empty single string that is not a list, return it as single evidence\n        if x != \"\":\n            return [x]\n        return [\"\"]\n    # other types -> stringify\n    return [str(x)]\n\nall_pairs = []         # list of (claim, evidence) pairs for model input\nrow_map = []           # for each pair, which original row index it belongs to\ncid_map = []           # store corresponding cid (for alignment)\nevidence_raw_map = []  # store original evidence text for that pair (string)\n\nfor idx, row in df.iterrows():\n    claim = row[\"claim\"]\n    raw_cids = row[\"cid\"]\n    # cid may be a single string like \"778,261,387\" or list. normalize to list of cid tokens (strings)\n    if pd.isna(raw_cids):\n        cid_tokens = [\"\"]\n    elif isinstance(raw_cids, list):\n        cid_tokens = [str(x) for x in raw_cids]\n    else:\n        # try to split by comma if it's a joined string\n        s = str(raw_cids).strip()\n        if (s.startswith(\"[\") and s.endswith(\"]\")):\n            try:\n                parsed = ast.literal_eval(s)\n                cid_tokens = [str(x) for x in parsed]\n            except Exception:\n                cid_tokens = [p.strip() for p in s.split(\",\") if p.strip() != \"\"]\n        else:\n            cid_tokens = [p.strip() for p in s.split(\",\") if p.strip() != \"\"]\n\n    evidences = parse_evidence_cell(row[\"evidence\"])  # list of evidence strings\n    # If number of evidences != number of cids, we still pair by position where possible.\n    # We'll create pairs for each evidence item. Also attach matching cid if exists, else empty.\n    for i, ev in enumerate(evidences):\n        all_pairs.append((claim, ev))\n        row_map.append(idx)\n        # choose cid token at same index if available else empty\n        cid_token = cid_tokens[i] if i < len(cid_tokens) else \"\"\n        cid_map.append(cid_token)\n        evidence_raw_map.append(ev)\n\n# -----------------------------\n# Run inference on all pairs in batches\n# -----------------------------\ndataset = SentencePairDataset(all_pairs, tokenizer, max_length=MAX_LENGTH)\ndataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n\npred_labels_int = []\nwith torch.no_grad():\n    for batch in tqdm(dataloader, desc=\"Predicting pair labels\"):\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        logits = outputs.logits if hasattr(outputs, \"logits\") else outputs[0]\n        preds = torch.argmax(logits, dim=1).cpu().tolist()\n        pred_labels_int.extend(preds)\n\n# Sanity check\nif len(pred_labels_int) != len(all_pairs):\n    raise RuntimeError(\"Prediction count mismatch: {} preds vs {} pairs\".format(len(pred_labels_int), len(all_pairs)))\n\n# -----------------------------\n# Aggregate predicted labels back to original rows\n# -----------------------------\n# prepare a list-of-lists for predicted labels per original row index\npreds_by_row = [[] for _ in range(len(df))]\nfor pair_idx, row_idx in enumerate(row_map):\n    lab_int = pred_labels_int[pair_idx]\n    lab_str = INT2LABEL.get(int(lab_int), str(lab_int))\n    preds_by_row[row_idx].append(lab_str)\n\n# create output dataframe: keep original columns and add pred_label column (stringified list)\nout_df = df.copy()\nout_df[\"pred_label\"] = [preds_by_row[i] for i in range(len(out_df))]\n\n# If you prefer to save pred_label as a string (CSV-friendly), convert lists to JSON-like strings\nout_df[\"pred_label\"] = out_df[\"pred_label\"].apply(lambda lst: \"[\" + \", \".join(f\"'{x}'\" for x in lst) + \"]\")\n\n# Save\nout_df.to_csv(OUT_CSV, index=False, encoding=\"utf-8\")\nprint(\"Saved output to\", OUT_CSV)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"temp = pd.read_csv(\"predictions_with_pair_labels_top10.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"temp.iloc[2]['evidence'] ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport ast\nimport re\n\n# ---------- CONFIG ----------\nINPUT_CSV = \"predictions_with_pair_labels_top10.csv\"\n\n# ---------- helpers ----------\ndef safe_literal_eval(s):\n    if pd.isna(s):\n        return []\n    if isinstance(s, list):\n        return s\n    if not isinstance(s, str):\n        return [str(s)]\n    s = s.strip()\n    if s == \"\":\n        return []\n    try:\n        val = ast.literal_eval(s)\n        if isinstance(val, (list, tuple)):\n            return list(val)\n        return [val]\n    except Exception:\n        parts = [p.strip() for p in s.split(\",\") if p.strip() != \"\"]\n        return parts if parts else [s]\n\ndef normalize_text(s):\n    if s is None:\n        s = \"\"\n    s = str(s).strip().lower()\n    s = re.sub(r\"[^\\w\\s]\", \"\", s)\n    s = \" \".join(s.split())\n    return s\n\n# ---------- load ----------\ndf = pd.read_csv(INPUT_CSV)\nfor col in (\"pred_label\", \"evidence\", \"gold_evidence\", \"gold_label\"):\n    if col not in df.columns:\n        raise KeyError(f\"Missing column: {col}\")\n\n# ---------- loop over top-K ----------\nfor TOP_K in range(1, 11):\n    final_labels = []\n    final_evidences = []\n    vc_flags = []\n    er_flags = []\n    strict_flags = []\n\n    for _, row in df.iterrows():\n        pred_list = safe_literal_eval(row[\"pred_label\"])\n        evid_list = safe_literal_eval(row[\"evidence\"])\n\n        pred_list = [(\"\" if (x is None) else str(x)) for x in pred_list]\n        evid_list = [(\"\" if (x is None or (isinstance(x, float) and pd.isna(x))) else str(x)) for x in evid_list]\n\n        pred_trunc = pred_list[:TOP_K]\n        evid_trunc = evid_list[:TOP_K]\n\n        chosen_idx = None\n        for i, lab in enumerate(pred_trunc):\n            if str(lab).strip().upper() != \"NEI\":\n                chosen_idx = i\n                chosen_label = lab\n                break\n\n        if chosen_idx is None:\n            final_label = \"NEI\"\n            final_evidence = evid_trunc[0] if len(evid_trunc) > 0 else (evid_list[0] if len(evid_list) > 0 else \"\")\n        else:\n            final_label = str(chosen_label)\n            final_evidence = evid_trunc[chosen_idx] if chosen_idx < len(evid_trunc) else \"\"\n\n        final_labels.append(final_label)\n        final_evidences.append(final_evidence)\n\n        gold_label = \"\" if pd.isna(row.get(\"gold_label\", \"\")) else str(row.get(\"gold_label\", \"\"))\n        vc = normalize_text(final_label) == normalize_text(gold_label)\n        vc_flags.append(vc)\n\n        gold_ev = \"\" if pd.isna(row.get(\"gold_evidence\", \"\")) else str(row.get(\"gold_evidence\", \"\"))\n        er = normalize_text(final_evidence) == normalize_text(gold_ev)\n        er_flags.append(er)\n\n        strict_flags.append(vc and er)\n\n    N = len(df)\n    strict_count = sum(strict_flags)\n    vc_count = sum(vc_flags)\n    er_count = sum(er_flags)\n    strict_acc = strict_count / N if N else 0.0\n    vc_acc = vc_count / N if N else 0.0\n    er_acc = er_count / N if N else 0.0\n\n    print(f\"TOP_K = {TOP_K}\")\n    print(f\"Total samples: {N}\")\n    print(f\"Verdict correct (VC): {vc_count} / {N}  (VC acc = {vc_acc:.4f})\")\n    print(f\"Evidence correct (ER): {er_count} / {N}  (ER acc = {er_acc:.4f})\")\n    print(f\"Strict correct (both VC & ER): {strict_count} / {N}  (Strict acc = {strict_acc:.4f})\")\n    print(\"=\" * 22)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport ast\nimport re\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# ---------- CONFIG ----------\nINPUT_CSV = \"predictions_with_pair_labels_top10.csv\"\n\n# ---------- helpers ----------\ndef safe_literal_eval(s):\n    if pd.isna(s):\n        return []\n    if isinstance(s, list):\n        return s\n    if not isinstance(s, str):\n        return [str(s)]\n    s = s.strip()\n    if s == \"\":\n        return []\n    try:\n        val = ast.literal_eval(s)\n        if isinstance(val, (list, tuple)):\n            return list(val)\n        return [val]\n    except Exception:\n        parts = [p.strip() for p in s.split(\",\") if p.strip() != \"\"]\n        return parts if parts else [s]\n\ndef normalize_text(s):\n    if s is None:\n        s = \"\"\n    s = str(s).strip().lower()\n    s = re.sub(r\"[^\\w\\s]\", \"\", s)\n    s = \" \".join(s.split())\n    return s\n\n# ---------- load ----------\ndf = pd.read_csv(INPUT_CSV)\nfor col in (\"pred_label\", \"evidence\", \"gold_evidence\", \"gold_label\"):\n    if col not in df.columns:\n        raise KeyError(f\"Missing column: {col}\")\n\n# ---------- loop over top-K ----------\nfor TOP_K in range(1, 11):\n    final_labels = []\n    final_evidences = []\n    vc_flags = []\n    er_flags = []\n    strict_flags = []\n    gold_labels_clean = []\n\n    for _, row in df.iterrows():\n        pred_list = safe_literal_eval(row[\"pred_label\"])\n        evid_list = safe_literal_eval(row[\"evidence\"])\n\n        pred_list = [(\"\" if (x is None) else str(x)) for x in pred_list]\n        evid_list = [(\"\" if (x is None or (isinstance(x, float) and pd.isna(x))) else str(x)) for x in evid_list]\n\n        pred_trunc = pred_list[:TOP_K]\n        evid_trunc = evid_list[:TOP_K]\n\n        chosen_idx = None\n        for i, lab in enumerate(pred_trunc):\n            if str(lab).strip().upper() != \"NEI\":\n                chosen_idx = i\n                chosen_label = lab\n                break\n\n        if chosen_idx is None:\n            final_label = \"NEI\"\n            final_evidence = evid_trunc[0] if len(evid_trunc) > 0 else (evid_list[0] if len(evid_list) > 0 else \"\")\n        else:\n            final_label = str(chosen_label)\n            final_evidence = evid_trunc[chosen_idx] if chosen_idx < len(evid_trunc) else \"\"\n\n        final_labels.append(final_label)\n        final_evidences.append(final_evidence)\n\n        gold_label = \"\" if pd.isna(row.get(\"gold_label\", \"\")) else str(row.get(\"gold_label\", \"\"))\n        gold_labels_clean.append(gold_label)\n\n        vc = normalize_text(final_label) == normalize_text(gold_label)\n        vc_flags.append(vc)\n\n        gold_ev = \"\" if pd.isna(row.get(\"gold_evidence\", \"\")) else str(row.get(\"gold_evidence\", \"\"))\n        er = normalize_text(final_evidence) == normalize_text(gold_ev)\n        er_flags.append(er)\n\n        strict_flags.append(vc and er)\n\n    # ---------- compute metrics ----------\n    N = len(df)\n    strict_count = sum(strict_flags)\n    vc_count = sum(vc_flags)\n    er_count = sum(er_flags)\n    strict_acc = strict_count / N if N else 0.0\n    vc_acc = vc_count / N if N else 0.0\n    er_acc = er_count / N if N else 0.0\n\n    print(f\"\\nTOP_K = {TOP_K}\")\n    print(f\"Total samples: {N}\")\n    print(f\"Verdict correct (VC): {vc_count} / {N}  (VC acc = {vc_acc:.4f})\")\n    print(f\"Evidence correct (ER): {er_count} / {N}  (ER acc = {er_acc:.4f})\")\n    print(f\"Strict correct (both VC & ER): {strict_count} / {N}  (Strict acc = {strict_acc:.4f})\")\n\n    # ---------- confusion matrix ----------\n    y_true = [normalize_text(x) for x in gold_labels_clean]\n    y_pred = [normalize_text(x) for x in final_labels]\n    labels_order = [\"support\", \"refute\", \"nei\"]\n\n    cm = confusion_matrix(y_true, y_pred, labels=labels_order)\n    print(\"\\nConfusion Matrix (rows=true, cols=pred):\")\n    print(pd.DataFrame(cm, index=[f\"T_{l}\" for l in labels_order],\n                          columns=[f\"P_{l}\" for l in labels_order]))\n\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_true, y_pred, labels=labels_order, digits=4))\n    print(\"=\" * 40)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Load the CSV file\ndf = pd.read_csv(\"/kaggle/input/predictions-viwiki-xlm-oneshot-top10/predictions_viwiki_XLM_oneshot_top10.csv\")\n\n# Filter rows where 'evidence' is NaN\nna_samples = df[df['evidence'].isna()]\n\n# Print how many there are\nprint(f\"Number of rows with evidence == NaN: {len(na_samples)}\\n\")\n\n# Display the first few examples\nprint(na_samples)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"temp.iloc[175]","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}